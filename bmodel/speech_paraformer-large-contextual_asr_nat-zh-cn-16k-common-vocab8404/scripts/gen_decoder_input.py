import numpy as np
import torch

enc = torch.randn(10, 1100, 512)
enc_len = torch.arange(start=200, end=1200, step=100, dtype=torch.int32)
pre_acoustic_embeds = torch.randn(10, 600, 512)
pre_token_length = torch.arange(start=60, end=660, step=60, dtype=torch.int32)
bias_embed = torch.randn(10, 1, 512)
enc = enc.detach().numpy()
enc_len = enc_len.detach().numpy()
pre_acoustic_embeds = pre_acoustic_embeds.detach().numpy()
pre_token_length = pre_token_length.detach().numpy()
bias_embed = bias_embed.detach().numpy()
np.savez("input_10batch.npz", enc=enc, enc_len=enc_len, pre_acoustic_embeds=pre_acoustic_embeds, pre_token_length=pre_token_length, bias_embed=bias_embed)

enc = torch.randn(1, 1100, 512)
enc_len = torch.tensor([1100], dtype=torch.int32)
pre_acoustic_embeds = torch.randn(1, 600, 512)
pre_token_length = torch.tensor([600], dtype=torch.int32)
bias_embed = torch.randn(1, 1, 512)
enc = enc.detach().numpy()
enc_len = enc_len.detach().numpy()
pre_acoustic_embeds = pre_acoustic_embeds.detach().numpy()
pre_token_length = pre_token_length.detach().numpy()
bias_embed = bias_embed.detach().numpy()
np.savez("input_1batch.npz", enc=enc, enc_len=enc_len, pre_acoustic_embeds=pre_acoustic_embeds, pre_token_length=pre_token_length, bias_embed=bias_embed)
